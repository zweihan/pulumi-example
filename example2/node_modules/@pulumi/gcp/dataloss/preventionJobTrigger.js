"use strict";
// *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***
Object.defineProperty(exports, "__esModule", { value: true });
exports.PreventionJobTrigger = void 0;
const pulumi = require("@pulumi/pulumi");
const utilities = require("../utilities");
/**
 * A job trigger configuration.
 *
 * To get more information about JobTrigger, see:
 *
 * * [API documentation](https://cloud.google.com/dlp/docs/reference/rest/v2/projects.jobTriggers)
 * * How-to Guides
 *     * [Official Documentation](https://cloud.google.com/dlp/docs/creating-job-triggers)
 *
 * ## Example Usage
 * ### Dlp Job Trigger Basic
 *
 * ```typescript
 * import * as pulumi from "@pulumi/pulumi";
 * import * as gcp from "@pulumi/gcp";
 *
 * const basic = new gcp.dataloss.PreventionJobTrigger("basic", {
 *     description: "Description",
 *     displayName: "Displayname",
 *     inspectJob: {
 *         actions: [{
 *             saveFindings: {
 *                 outputConfig: {
 *                     table: {
 *                         datasetId: "dataset",
 *                         projectId: "project",
 *                     },
 *                 },
 *             },
 *         }],
 *         inspectTemplateName: "fake",
 *         storageConfig: {
 *             cloudStorageOptions: {
 *                 fileSet: {
 *                     url: "gs://mybucket/directory/",
 *                 },
 *             },
 *         },
 *     },
 *     parent: "projects/my-project-name",
 *     triggers: [{
 *         schedule: {
 *             recurrencePeriodDuration: "86400s",
 *         },
 *     }],
 * });
 * ```
 * ### Dlp Job Trigger Bigquery Row Limit
 *
 * ```typescript
 * import * as pulumi from "@pulumi/pulumi";
 * import * as gcp from "@pulumi/gcp";
 *
 * const bigqueryRowLimit = new gcp.dataloss.PreventionJobTrigger("bigqueryRowLimit", {
 *     description: "Description",
 *     displayName: "Displayname",
 *     inspectJob: {
 *         actions: [{
 *             saveFindings: {
 *                 outputConfig: {
 *                     table: {
 *                         datasetId: "dataset",
 *                         projectId: "project",
 *                     },
 *                 },
 *             },
 *         }],
 *         inspectTemplateName: "fake",
 *         storageConfig: {
 *             bigQueryOptions: {
 *                 rowsLimit: 1000,
 *                 sampleMethod: "RANDOM_START",
 *                 tableReference: {
 *                     datasetId: "dataset",
 *                     projectId: "project",
 *                     tableId: "table_to_scan",
 *                 },
 *             },
 *         },
 *     },
 *     parent: "projects/my-project-name",
 *     triggers: [{
 *         schedule: {
 *             recurrencePeriodDuration: "86400s",
 *         },
 *     }],
 * });
 * ```
 * ### Dlp Job Trigger Bigquery Row Limit Percentage
 *
 * ```typescript
 * import * as pulumi from "@pulumi/pulumi";
 * import * as gcp from "@pulumi/gcp";
 *
 * const bigqueryRowLimitPercentage = new gcp.dataloss.PreventionJobTrigger("bigqueryRowLimitPercentage", {
 *     description: "Description",
 *     displayName: "Displayname",
 *     inspectJob: {
 *         actions: [{
 *             saveFindings: {
 *                 outputConfig: {
 *                     table: {
 *                         datasetId: "dataset",
 *                         projectId: "project",
 *                     },
 *                 },
 *             },
 *         }],
 *         inspectTemplateName: "fake",
 *         storageConfig: {
 *             bigQueryOptions: {
 *                 rowsLimitPercent: 50,
 *                 sampleMethod: "RANDOM_START",
 *                 tableReference: {
 *                     datasetId: "dataset",
 *                     projectId: "project",
 *                     tableId: "table_to_scan",
 *                 },
 *             },
 *         },
 *     },
 *     parent: "projects/my-project-name",
 *     triggers: [{
 *         schedule: {
 *             recurrencePeriodDuration: "86400s",
 *         },
 *     }],
 * });
 * ```
 * ### Dlp Job Trigger Job Notification Emails
 *
 * ```typescript
 * import * as pulumi from "@pulumi/pulumi";
 * import * as gcp from "@pulumi/gcp";
 *
 * const jobNotificationEmails = new gcp.dataloss.PreventionJobTrigger("jobNotificationEmails", {
 *     description: "Description for the job_trigger created by terraform",
 *     displayName: "TerraformDisplayName",
 *     inspectJob: {
 *         actions: [{
 *             jobNotificationEmails: {},
 *         }],
 *         inspectTemplateName: "sample-inspect-template",
 *         storageConfig: {
 *             cloudStorageOptions: {
 *                 fileSet: {
 *                     url: "gs://mybucket/directory/",
 *                 },
 *             },
 *         },
 *     },
 *     parent: "projects/my-project-name",
 *     triggers: [{
 *         schedule: {
 *             recurrencePeriodDuration: "86400s",
 *         },
 *     }],
 * });
 * ```
 * ### Dlp Job Trigger Deidentify
 *
 * ```typescript
 * import * as pulumi from "@pulumi/pulumi";
 * import * as gcp from "@pulumi/gcp";
 *
 * const defaultDataset = new gcp.bigquery.Dataset("defaultDataset", {
 *     datasetId: "tf_test",
 *     friendlyName: "terraform-test",
 *     description: "Description for the dataset created by terraform",
 *     location: "US",
 *     defaultTableExpirationMs: 3600000,
 *     labels: {
 *         env: "default",
 *     },
 * });
 * const defaultTable = new gcp.bigquery.Table("defaultTable", {
 *     datasetId: defaultDataset.datasetId,
 *     tableId: "tf_test",
 *     deletionProtection: false,
 *     timePartitioning: {
 *         type: "DAY",
 *     },
 *     labels: {
 *         env: "default",
 *     },
 *     schema: `    [
 *     {
 *       "name": "quantity",
 *       "type": "NUMERIC",
 *       "mode": "NULLABLE",
 *       "description": "The quantity"
 *     },
 *     {
 *       "name": "name",
 *       "type": "STRING",
 *       "mode": "NULLABLE",
 *       "description": "Name of the object"
 *     }
 *     ]
 * `,
 * });
 * const deidentify = new gcp.dataloss.PreventionJobTrigger("deidentify", {
 *     parent: "projects/my-project-name",
 *     description: "Description for the job_trigger created by terraform",
 *     displayName: "TerraformDisplayName",
 *     triggers: [{
 *         schedule: {
 *             recurrencePeriodDuration: "86400s",
 *         },
 *     }],
 *     inspectJob: {
 *         inspectTemplateName: "sample-inspect-template",
 *         actions: [{
 *             deidentify: {
 *                 cloudStorageOutput: "gs://samplebucket/dir/",
 *                 fileTypesToTransforms: [
 *                     "CSV",
 *                     "TSV",
 *                 ],
 *                 transformationDetailsStorageConfig: {
 *                     table: {
 *                         projectId: "my-project-name",
 *                         datasetId: defaultDataset.datasetId,
 *                         tableId: defaultTable.tableId,
 *                     },
 *                 },
 *                 transformationConfig: {
 *                     deidentifyTemplate: "sample-deidentify-template",
 *                     imageRedactTemplate: "sample-image-redact-template",
 *                     structuredDeidentifyTemplate: "sample-structured-deidentify-template",
 *                 },
 *             },
 *         }],
 *         storageConfig: {
 *             cloudStorageOptions: {
 *                 fileSet: {
 *                     url: "gs://mybucket/directory/",
 *                 },
 *             },
 *         },
 *     },
 * });
 * ```
 * ### Dlp Job Trigger Hybrid
 *
 * ```typescript
 * import * as pulumi from "@pulumi/pulumi";
 * import * as gcp from "@pulumi/gcp";
 *
 * const hybridTrigger = new gcp.dataloss.PreventionJobTrigger("hybridTrigger", {
 *     inspectJob: {
 *         actions: [{
 *             saveFindings: {
 *                 outputConfig: {
 *                     table: {
 *                         datasetId: "dataset",
 *                         projectId: "project",
 *                     },
 *                 },
 *             },
 *         }],
 *         inspectTemplateName: "fake",
 *         storageConfig: {
 *             hybridOptions: {
 *                 description: "Hybrid job trigger for data from the comments field of a table that contains customer appointment bookings",
 *                 labels: {
 *                     env: "prod",
 *                 },
 *                 requiredFindingLabelKeys: ["appointment-bookings-comments"],
 *                 tableOptions: {
 *                     identifyingFields: [{
 *                         name: "booking_id",
 *                     }],
 *                 },
 *             },
 *         },
 *     },
 *     parent: "projects/my-project-name",
 *     triggers: [{
 *         manual: {},
 *     }],
 * });
 * ```
 * ### Dlp Job Trigger Publish To Stackdriver
 *
 * ```typescript
 * import * as pulumi from "@pulumi/pulumi";
 * import * as gcp from "@pulumi/gcp";
 *
 * const publishToStackdriver = new gcp.dataloss.PreventionJobTrigger("publishToStackdriver", {
 *     description: "Description for the job_trigger created by terraform",
 *     displayName: "TerraformDisplayName",
 *     inspectJob: {
 *         actions: [{
 *             publishToStackdriver: {},
 *         }],
 *         inspectTemplateName: "sample-inspect-template",
 *         storageConfig: {
 *             cloudStorageOptions: {
 *                 fileSet: {
 *                     url: "gs://mybucket/directory/",
 *                 },
 *             },
 *         },
 *     },
 *     parent: "projects/my-project-name",
 *     triggers: [{
 *         schedule: {
 *             recurrencePeriodDuration: "86400s",
 *         },
 *     }],
 * });
 * ```
 *
 * ## Import
 *
 * JobTrigger can be imported using any of these accepted formats
 *
 * ```sh
 *  $ pulumi import gcp:dataloss/preventionJobTrigger:PreventionJobTrigger default {{parent}}/jobTriggers/{{name}}
 * ```
 *
 * ```sh
 *  $ pulumi import gcp:dataloss/preventionJobTrigger:PreventionJobTrigger default {{parent}}/{{name}}
 * ```
 */
class PreventionJobTrigger extends pulumi.CustomResource {
    /**
     * Get an existing PreventionJobTrigger resource's state with the given name, ID, and optional extra
     * properties used to qualify the lookup.
     *
     * @param name The _unique_ name of the resulting resource.
     * @param id The _unique_ provider ID of the resource to lookup.
     * @param state Any extra arguments used during the lookup.
     * @param opts Optional settings to control the behavior of the CustomResource.
     */
    static get(name, id, state, opts) {
        return new PreventionJobTrigger(name, state, Object.assign(Object.assign({}, opts), { id: id }));
    }
    /**
     * Returns true if the given object is an instance of PreventionJobTrigger.  This is designed to work even
     * when multiple copies of the Pulumi SDK have been loaded into the same process.
     */
    static isInstance(obj) {
        if (obj === undefined || obj === null) {
            return false;
        }
        return obj['__pulumiType'] === PreventionJobTrigger.__pulumiType;
    }
    constructor(name, argsOrState, opts) {
        let resourceInputs = {};
        opts = opts || {};
        if (opts.id) {
            const state = argsOrState;
            resourceInputs["createTime"] = state ? state.createTime : undefined;
            resourceInputs["description"] = state ? state.description : undefined;
            resourceInputs["displayName"] = state ? state.displayName : undefined;
            resourceInputs["inspectJob"] = state ? state.inspectJob : undefined;
            resourceInputs["lastRunTime"] = state ? state.lastRunTime : undefined;
            resourceInputs["name"] = state ? state.name : undefined;
            resourceInputs["parent"] = state ? state.parent : undefined;
            resourceInputs["status"] = state ? state.status : undefined;
            resourceInputs["triggers"] = state ? state.triggers : undefined;
            resourceInputs["updateTime"] = state ? state.updateTime : undefined;
        }
        else {
            const args = argsOrState;
            if ((!args || args.parent === undefined) && !opts.urn) {
                throw new Error("Missing required property 'parent'");
            }
            if ((!args || args.triggers === undefined) && !opts.urn) {
                throw new Error("Missing required property 'triggers'");
            }
            resourceInputs["description"] = args ? args.description : undefined;
            resourceInputs["displayName"] = args ? args.displayName : undefined;
            resourceInputs["inspectJob"] = args ? args.inspectJob : undefined;
            resourceInputs["parent"] = args ? args.parent : undefined;
            resourceInputs["status"] = args ? args.status : undefined;
            resourceInputs["triggers"] = args ? args.triggers : undefined;
            resourceInputs["createTime"] = undefined /*out*/;
            resourceInputs["lastRunTime"] = undefined /*out*/;
            resourceInputs["name"] = undefined /*out*/;
            resourceInputs["updateTime"] = undefined /*out*/;
        }
        opts = pulumi.mergeOptions(utilities.resourceOptsDefaults(), opts);
        super(PreventionJobTrigger.__pulumiType, name, resourceInputs, opts);
    }
}
exports.PreventionJobTrigger = PreventionJobTrigger;
/** @internal */
PreventionJobTrigger.__pulumiType = 'gcp:dataloss/preventionJobTrigger:PreventionJobTrigger';
//# sourceMappingURL=preventionJobTrigger.js.map